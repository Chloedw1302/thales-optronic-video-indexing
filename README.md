# ğŸ¥ Thales Video Indexing

## ğŸ“˜ Description

Ce projet a pour objectif de crÃ©er une **base de vidÃ©os annotÃ©e automatiquement** Ã  partir dâ€™un dataset interne.  
Deux pipelines sont utilisÃ©s en parallÃ¨le :  
- **Speech-to-Text (STT)** pour la transcription et la traduction de lâ€™audio.  
- **Image-to-Text (Vision)** pour la description des frames et la dÃ©tection dâ€™objets.  

Le rÃ©sultat final est un fichier unique **`metadata_final.csv`** contenant les mÃ©tadonnÃ©es fusionnÃ©es (audio + vidÃ©o).

---

## ğŸ§± Structure du projet

```bash
thales-video-indexing/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ videos/                       # .mp4 sources (non versionnÃ©s)
â”‚  â”œâ”€ audio/                        # .wav extraits automatiquement
â”‚  â”œâ”€ frames/                       # frames extraites automatiquement
â”‚  â””â”€ metadata/                     # mÃ©tadonnÃ©es & sorties finales
â”‚      â”œâ”€ manifest.csv              # inventaire auto des vidÃ©os
â”‚      â”œâ”€ stt_<video_id>.csv        # rÃ©sultats speech-to-text
â”‚      â”œâ”€ vision_<video_id>.csv     # rÃ©sultats image-to-text / dÃ©tection
â”‚      â””â”€ metadata_final.csv        # fichier fusionnÃ© final
â”‚
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_speech_to_text.ipynb       # pipeline audio (Whisper/Faster-Whisper)
â”‚  â””â”€ 02_video_pipeline.ipynb       # pipeline vidÃ©o (VLM/objets)
â”‚
â””â”€ src/
   â”œâ”€ __init__.py                   # vide (nÃ©cessaire pour les imports)
   â”œâ”€ dataset_preparation.py        # prÃ©paration dataset (scan, manifest, frames, audio)
   â””â”€ fusion.py                     # fusion STT + Vision â†’ metadata_final.csv
```

---

## âš™ï¸ Installation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/<ton-utilisateur>/thales-video-indexing.git
cd thales-video-indexing

# CrÃ©er un environnement virtuel (optionnel)
python -m venv venv
source venv/bin/activate   # (Linux/macOS)
venv\Scripts\activate      # (Windows)

# Installer les dÃ©pendances
pip install -r requirements.txt
```

---

## ğŸš€ Utilisation

### 1ï¸âƒ£ PrÃ©paration du dataset

Ce script scanne le dossier `data/videos/`, crÃ©e le `manifest.csv`, extrait des frames et des pistes audio.  
```bash
python -m src.dataset_preparation --scan --manifest --extract-frames --extract-audio
```

### 2ï¸âƒ£ Lancer les pipelines (dans Jupyter)

- **01_speech_to_text.ipynb** â†’ gÃ©nÃ¨re `stt_<video_id>.csv`  
- **02_video_pipeline.ipynb** â†’ gÃ©nÃ¨re `vision_<video_id>.csv`

### 3ï¸âƒ£ Fusion des rÃ©sultats

Fusionne les rÃ©sultats audio et vidÃ©o dans un seul CSV final :  
```bash
python -m src.fusion
```

ğŸŸ¢ Sortie :  
`data/metadata/metadata_final.csv`

---

## ğŸ“Š RÃ©sultat attendu

Le fichier `metadata_final.csv` regroupe toutes les mÃ©tadonnÃ©es audio et vidÃ©o sous un format standardisÃ©, par exemple :

| video_id | timestamp_frame | audio_transcription | video_description | video_objects | confidence |
|-----------|-----------------|---------------------|-------------------|----------------|-------------|
| 001 | 12.0 | "A drone is flying." | "A small drone appears in the sky." | drone | 0.87 |

---

## ğŸ§© Auteurs
- **ChloÃ© de Wilde** â€” Data & AI Engineering  
- Projet acadÃ©mique Thales â€“ *Video Indexing Pipeline*  

---

## ğŸ›¡ï¸ Licence
Ce projet est rÃ©servÃ© Ã  un usage acadÃ©mique et interne.
